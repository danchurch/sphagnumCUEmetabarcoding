## let's take a look at the sequences from Werner. 
## = get an OTU table, check predictors  NMS/permanova etc. 
## if there is anything there, contact florian hartig and get serious with jsdm

## pertinent other scripts (officecomp)
/home/daniel/Documents/projects/mossSymbiosis/nostoc/totalCyanoCommunity/processIllumina16s.txt
/home/daniel/Documents/teaching/funmic/FunctionalMicrobiomePractical/funmic2025/scripts/metabarcoding.txt

## wd
cd /home/daniel/Documents/projects/wernerSphagnum/sequenceAnalysis

## raw reads are here:
cd /media/vol/wernerSphagnumSequences/

## let's make symbolic links to these, see if we can avoid doubling storage

cd /home/daniel/Documents/projects/wernerSphagnum/sampleData/sequencingSamples/originalSeqs

destinationDir="/home/daniel/Documents/projects/wernerSphagnum/sampleData/sequencingSamples/originalSeqs/"
originalSeqDir="/media/vol/wernerSphagnumSequences/"
cd ${originalSeqDir}

for i in *; do 
  ln -s ${originalSeqDir}$i ${destinationDir}$i
done

## not sure if we can do everything via links, let's try 

## we had two samples from moss cyanobacterial culture project, don't need these:

cd /home/daniel/Documents/projects/wernerSphagnum/sampleData/sequencingSamples/originalSeqs/
rm Oemik-002018* Oemik-002019*

## how do the qualities look?:
## let's combine them all:

cd /home/daniel/Documents/projects/wernerSphagnum/sampleData/sequencingSamples/combinedSamps
cat ${destinationDir}* > comboSphagnumRawReads.fastq.gz

fastqc -o . -t 2 comboSphagnumRawReads.fastq.gz 

## looks great, maybe trim off the final 5 bp or so

## where is our sample metadata?
/home/daniel/Documents/projects/wernerSphagnum/sampleData

## let's trim the primers


cd /home/daniel/Documents/projects/wernerSphagnum/sampleData/sequencingSamples/originalSeqs/

outputDir=/home/daniel/Documents/projects/wernerSphagnum/sampleData/sequencingSamples/trimmed_reads
for inputFastq in *; do
    cutadapt --rc \
        -g TCGTGYCAGCMGCCGCGGTAA \
        --length 280 \
        -a GGACTACNVGGGTWTCTAAT \
        -o ${outputDir}${inputFastq} \
           ${inputFastq}
done &> test.log

## go to dada2 


R
library(dada2)
library(phyloseq)
library(Biostrings)
library(ape)
library(ggplot2)
library(RColorBrewer)

## where are our trimmed reads?

setwd("/home/daniel/Documents/projects/wernerSphagnum/sampleData/sequencingSamples/trimmed_reads")

fileNames <- list.files(pattern="fastq.gz")

## do some quality filtering on these reads before denoising

## where should we put these?
filterPath <- "/home/daniel/Documents/projects/wernerSphagnum/sampleData/sequencingSamples/filteredReads"

out <- filterAndTrim(fileNames, filterPath,
              maxN=0, maxEE=2, truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE)

## we lose a lot
sum(out[,2]) / sum(out[,1]) ## ~60% reads retained.

setwd("/home/daniel/Documents/projects/wernerSphagnum/sampleData/sequencingSamples/filteredReads")

err <- learnErrors(fileNames, multithread=TRUE)

save(err, file="../err.rda")

plotErrors(err, nominalQ=TRUE)


## this step defines our ASVs:
dadaF <- dada(fileNames, err=err, pool=TRUE, multithread=TRUE)


save(dadaF, file="/home/daniel/Documents/projects/wernerSphagnum/sequenceAnalysis/dadaPeat.rda")


## this is taking forever. I think because I only have four cores on this machine.
## Can we repeat it on the optiplex or nanoComp?
## take a break, if it doesn't finish by then port it over. 

## now that we have ASVs, we can make an OTU table:

seqtab <- makeSequenceTable(dadaF)

seqtab

seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)

save(seqtab.nochim, file="/home/daniel/Documents/projects/wernerSphagnum/sequenceAnalysis/seqtab.nochimPeat.rda")

load(file="/home/daniel/Documents/projects/wernerSphagnum/sequenceAnalysis/seqtab.nochimPeat.rda")

## make row names pretty. Here we need our sample names, etc. 

homedir="/home/daniel/Documents/projects/wernerSphagnum/sequenceAnalysis/"
## eco info here

envData <- read.csv(paste0(homedir,"envDataPeat.csv"))
sampleLabels <- read.csv(paste0(homedir,"sampleNames.csv"))
## with this, can we clean up our row names?

## actually, we don't need them:
rownames(seqtab.nochim) <- gsub("trimmed_reads.*_S", "S", rownames(seqtab.nochim)) |> 
gsub("_L.*fastq.gz","",x=_)

path2silvaDB <- "/media/vol/phylo_dbs/silva/silva138.2/silva_nr99_v138.2_toGenus_trainset.fa"

taxa <- assignTaxonomy(seqtab.nochim, path2silvaDB, multithread=TRUE)

ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), tax_table(taxa))

dna <- Biostrings::DNAStringSet(taxa_names(ps))
names(dna) <- taxa_names(ps)
ps <- merge_phyloseq(ps, dna)
## give our ASVs pretty names instead of DNA sequences:
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))

## let's add our "environmental data" (woefully incomplete at this point).
## and our tree, also still really raw: 

envData <- read.csv(paste0(homedir,"envDataPeat.csv"))

envData <- data.frame(envData, row.names = "SampleName")
envData$DepthSection <- as.numeric(envData$DepthSection)
sample_data(ps) = envData
save(ps, file="/home/daniel/Documents/projects/wernerSphagnum/sequenceAnalysis/peat16sPS.rda")

sampleLabels <- read.csv(paste0(homedir,"sampleNames.csv"))

str(envData)



load(file="/home/daniel/Documents/projects/wernerSphagnum/sequenceAnalysis/peat16sPS.rda")

rank_names(ps)

tax_table(ps)["ASV1",]

tax_table(ps)["ASV4927",]

tax_table(ps)["ASV1",]

tax_table(ps)["ASV17",] 

tax_table(ps)["ASV20",]

tax_table(ps)[1:200,"Genus"]

## our most common bacteria are Ralstonia, the first 20 or so. Seems fishy. 

###### run alignment ######

## let's get the alignment running overnight, another brain-free process we can do for free.

## do it one the nanoComp:

conda create -n ssu-align -c bioconda ssu-align 

setwd("/home/daniel/Documents/projects/wernerSphagnum/sequenceAnalysis/")
rs <- refseq(ps)
writeXStringSet(rs,"wernerSphagnumRefSeqs.fa", format="fasta")


## get this file 

getFile=/home/daniel/Documents/projects/wernerSphagnum/sequenceAnalysis/wernerSphagnumRefSeqs.fa
putFile=/media/vol1/daniel/wernerPeat/
rsync -auv $getFile test@132.180.112.115:$putFile

cd /media/vol1/daniel/wernerPeat/

conda activate ssu-align

nohup ssu-align -n bacteria wernerSphagnumRefSeqs.fa wernerSphagnumRefSeqs_ali &

## to check on this remotely:


## then a strict mask, don't trust any ambiguous calls, because we are forcing the bacterial model on archea
ssu-mask --pf 0.9999 --pt 0.9999 wernerSphagnumRefSeqs_ali

## to get a fasta output of the alignment (what we probably need)
ssu-mask --stk2afa wernerSphagnumRefSeqs_ali

ssuAlignOut="/media/vol1/daniel/wernerPeat/wernerSphagnumRefSeqs_ali/wernerSphagnumRefSeqs_ali.bacteria.afa"
FastTree -gtr -nt < $ssuAlignOut > wernerPeatFastTree.nwk

## get it local:
getFile=/media/vol1/daniel/wernerPeat/wernerSphagnumRefSeqs_ali/wernerPeatFastTree.nwk
putFile=/home/daniel/Documents/projects/wernerSphagnum/sequenceAnalysis/
rsync -auv test@132.180.112.115:$getFile $putFile

## to add this, in R:

tax_table(ps)[,"Kingdom"]

tax_table(ps)['ASV5788',]


archFilter <- as.vector(tax_table(ps)[,"Kingdom"] == "Archaea")
archFilter[is.na(archFilter)] <- FALSE

archeaPS = prune_taxa(archFilter, ps)

aa = ape::read.tree("wernerPeatFastTree.nwk")

taxa_names(archeaPS)

rooted_tree = root(aa, outgroup = taxa_names(archeaPS), resolve.root = TRUE)
phy_tree(psCleanedUp) <- rooted_tree
plot_tree(psCleanedUp, color="Kingdom")
## meh, not working, looks like the archea didn't make it
## onto the tree. Work on this later

###### run alignment ######

## in the meantime, what does this data look like?

barplot(sample_sums(ps))


barplot(sort(sample_sums(ps), decreasing=TRUE))

barplot(sort(sample_sums(ps), decreasing=TRUE), cex.names=0.8, las=2)

sort(sample_names(ps))

## three samples essentially failed:

sample_data(ps)[c("S27","S28","S33")] 
## these are thermokarst:

## S27  AT2_43-63 Thermokarst            1 
## S28  AT2_63-83 Thermokarst            2 
## S33 AT3_80-100 Thermokarst            2 


## we want:

## 1 - taxonomic overview
## 2 - ordinations by the data we have

## let's normalize abundances a bit:
ps.prop <- transform_sample_counts(ps, function(otu) otu/sum(otu))

plot_bar(ps.prop, fill = "Kingdom") + 
  geom_bar(aes(color=Kingdom, fill=Kingdom), stat="identity", position="stack")

plot_richness(ps, measures=c("Chao1", "Shannon"))

ps.prop.ord <- ordinate(ps.prop, "NMDS", "bray")

aa <- plot_ordination(ps.prop, ps.prop.ord, color="Subsite")

## let's also get rid of controls and low abundance samples, and check both variables:

nonCfilt <- sample_data(ps.prop)$EcoCont != "Control"
ps.prop.noC <- prune_samples(nonCfilt, ps.prop)
nonLowAbuFilt <- !(sample_names(ps.prop.noC) %in% c("S27","S28","S33"))
ps.prop.noC <- prune_samples(nonLowAbuFilt, ps.prop.noC)


sample_data(ps)[c("S27","S28","S33")] 

ps.prop.noC.ord <- ordinate(ps.prop.noC, "NMDS", "bray")

bb <- plot_ordination(ps.prop.noC, ps.prop.noC.ord, 
   color="DepthSection",
   shape="Subsite",
)

lbs <- geom_text(label=sample_data(ps.prop.noC)$Core,
                 color = "black",
                 nudge_x = 0.05, nudge_y = 0.05,
                 check_overlap = T)
myPalette <- colorRampPalette(rev(brewer.pal(8, "YlOrBr")))
sc <- scale_colour_gradientn(colours = myPalette(100), limits=c(5, 0), trans="reverse")

png("ordinationPeat.png", width=1000, height=1000)
bb + sc + lbs + geom_point(size=5)
dev.off()

sessionInfo()

## interesting. What else?

## would be good to know where the methanogens are
## and what taxa seem to be most important in each of these

## use picrust to pick out the methanogens?
## for that we need a better tree. I don't our methanogens made it on there.

## can we do a quick differential abundance analysis? probably not. 
## maybe the best thing we can do is set up a notebook, so werner can
## see what's up as we go. 


############################


